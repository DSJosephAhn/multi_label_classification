{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804d2002",
   "metadata": {},
   "source": [
    "## Deep learning model forHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac631863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dropout, Dense, LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e56aab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d0e97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR= os.path.join(os.getcwd(), 'datasets', 'UCI_HAR_Dataset')\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "SIGNALS = [\"body_acc_x\", \"body_acc_y\", \"body_acc_z\",\n",
    "    \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\",\n",
    "    \"total_acc_x\", \"total_acc_y\", \"total_acc_z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef44376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename= DATADIR + f'/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(pd.read_csv(filename, delim_whitespace=True, header=None).values) \n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57d9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y(subset):\n",
    "    filename= DATADIR + f'/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = pd.read_csv(filename, delim_whitespace=True, header=None)[0]\n",
    "    return pd.get_dummies(y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3545f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "    return X_train, y_train, X_test,  y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec76081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up seed for random values\n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdeac594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ae3f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train, Y_train, X_test,  Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec1bd7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "#n_classes  = 6\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86b814e",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "209a8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 32)                5376      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "base_model = Sequential()\n",
    "# Configuring the parameters\n",
    "base_model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "base_model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "base_model.add(Dense(n_classes, activation='sigmoid'))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a184c334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "460/460 [==============================] - 65s 126ms/step - loss: 1.2344 - accuracy: 0.4879 - val_loss: 1.1078 - val_accuracy: 0.5582\n",
      "Epoch 2/30\n",
      "460/460 [==============================] - 57s 123ms/step - loss: 0.8177 - accuracy: 0.6876 - val_loss: 0.7322 - val_accuracy: 0.6936\n",
      "Epoch 3/30\n",
      "460/460 [==============================] - 56s 123ms/step - loss: 0.5887 - accuracy: 0.7722 - val_loss: 0.7198 - val_accuracy: 0.7282\n",
      "Epoch 4/30\n",
      "460/460 [==============================] - 57s 125ms/step - loss: 0.4635 - accuracy: 0.8354 - val_loss: 0.5766 - val_accuracy: 0.8161\n",
      "Epoch 5/30\n",
      "460/460 [==============================] - 56s 122ms/step - loss: 0.3928 - accuracy: 0.8742 - val_loss: 0.5724 - val_accuracy: 0.8470\n",
      "Epoch 6/30\n",
      "460/460 [==============================] - 55s 119ms/step - loss: 0.3350 - accuracy: 0.8977 - val_loss: 0.6085 - val_accuracy: 0.8422\n",
      "Epoch 7/30\n",
      "460/460 [==============================] - 56s 121ms/step - loss: 0.2798 - accuracy: 0.9143 - val_loss: 0.5032 - val_accuracy: 0.8592\n",
      "Epoch 8/30\n",
      "460/460 [==============================] - 56s 123ms/step - loss: 0.2528 - accuracy: 0.9177 - val_loss: 0.3278 - val_accuracy: 0.8914\n",
      "Epoch 9/30\n",
      "460/460 [==============================] - 56s 121ms/step - loss: 0.2045 - accuracy: 0.9372 - val_loss: 0.5606 - val_accuracy: 0.8643\n",
      "Epoch 10/30\n",
      "460/460 [==============================] - 55s 120ms/step - loss: 0.2222 - accuracy: 0.9298 - val_loss: 0.2859 - val_accuracy: 0.9043\n",
      "Epoch 11/30\n",
      "460/460 [==============================] - 63s 137ms/step - loss: 0.1878 - accuracy: 0.9342 - val_loss: 0.3376 - val_accuracy: 0.8873\n",
      "Epoch 12/30\n",
      "460/460 [==============================] - 65s 141ms/step - loss: 0.1678 - accuracy: 0.9425 - val_loss: 0.3453 - val_accuracy: 0.9043\n",
      "Epoch 13/30\n",
      "460/460 [==============================] - 65s 141ms/step - loss: 0.1854 - accuracy: 0.9407 - val_loss: 0.4838 - val_accuracy: 0.8901\n",
      "Epoch 14/30\n",
      "460/460 [==============================] - 66s 145ms/step - loss: 0.1713 - accuracy: 0.9418 - val_loss: 0.4875 - val_accuracy: 0.8992\n",
      "Epoch 15/30\n",
      "460/460 [==============================] - 67s 145ms/step - loss: 0.1627 - accuracy: 0.9450 - val_loss: 0.4324 - val_accuracy: 0.8880\n",
      "Epoch 16/30\n",
      "460/460 [==============================] - 66s 144ms/step - loss: 0.1500 - accuracy: 0.9463 - val_loss: 0.4528 - val_accuracy: 0.9013\n",
      "Epoch 17/30\n",
      "460/460 [==============================] - 67s 145ms/step - loss: 0.1676 - accuracy: 0.9453 - val_loss: 0.4551 - val_accuracy: 0.8856\n",
      "Epoch 18/30\n",
      "460/460 [==============================] - 66s 143ms/step - loss: 0.1569 - accuracy: 0.9470 - val_loss: 0.3479 - val_accuracy: 0.8938\n",
      "Epoch 19/30\n",
      "460/460 [==============================] - 69s 149ms/step - loss: 0.1531 - accuracy: 0.9470 - val_loss: 0.3543 - val_accuracy: 0.8979\n",
      "Epoch 20/30\n",
      "460/460 [==============================] - 67s 146ms/step - loss: 0.1574 - accuracy: 0.9445 - val_loss: 0.3136 - val_accuracy: 0.8982\n",
      "Epoch 21/30\n",
      "460/460 [==============================] - 65s 140ms/step - loss: 0.1430 - accuracy: 0.9479 - val_loss: 0.2816 - val_accuracy: 0.8999\n",
      "Epoch 22/30\n",
      "460/460 [==============================] - 67s 145ms/step - loss: 0.1417 - accuracy: 0.9479 - val_loss: 0.3251 - val_accuracy: 0.9131\n",
      "Epoch 23/30\n",
      "460/460 [==============================] - 62s 136ms/step - loss: 0.1409 - accuracy: 0.9483 - val_loss: 0.2818 - val_accuracy: 0.9121\n",
      "Epoch 24/30\n",
      "460/460 [==============================] - 67s 146ms/step - loss: 0.1435 - accuracy: 0.9487 - val_loss: 0.3063 - val_accuracy: 0.8982\n",
      "Epoch 25/30\n",
      "460/460 [==============================] - 63s 136ms/step - loss: 0.1456 - accuracy: 0.9484 - val_loss: 0.4696 - val_accuracy: 0.8904\n",
      "Epoch 26/30\n",
      "460/460 [==============================] - 67s 146ms/step - loss: 0.1354 - accuracy: 0.9502 - val_loss: 0.4652 - val_accuracy: 0.9108\n",
      "Epoch 27/30\n",
      "460/460 [==============================] - 65s 141ms/step - loss: 0.1471 - accuracy: 0.9487 - val_loss: 0.2528 - val_accuracy: 0.9203\n",
      "Epoch 28/30\n",
      "460/460 [==============================] - 65s 142ms/step - loss: 0.1389 - accuracy: 0.9490 - val_loss: 0.2940 - val_accuracy: 0.9087\n",
      "Epoch 29/30\n",
      "460/460 [==============================] - 66s 144ms/step - loss: 0.1360 - accuracy: 0.9497 - val_loss: 0.2864 - val_accuracy: 0.9067\n",
      "Epoch 30/30\n",
      "460/460 [==============================] - 65s 142ms/step - loss: 0.1278 - accuracy: 0.9531 - val_loss: 0.4523 - val_accuracy: 0.9084\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "base_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "History= base_model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b879b5",
   "metadata": {},
   "source": [
    "### Multi-layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ea6a8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 128, 32)           5376      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128, 32)           0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 28)                6832      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 28)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 174       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,382\n",
      "Trainable params: 12,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "lstm_model = Sequential()\n",
    "# Configuring the parameters\n",
    "lstm_model.add(LSTM(32,return_sequences=True,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "lstm_model.add(Dropout(0.5))\n",
    "\n",
    "lstm_model.add(LSTM(28,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "lstm_model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "lstm_model.add(Dense(n_classes, activation='sigmoid'))\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47580642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "460/460 [==============================] - 149s 297ms/step - loss: 1.1395 - accuracy: 0.5384 - val_loss: 0.8153 - val_accuracy: 0.7102\n",
      "Epoch 2/30\n",
      "460/460 [==============================] - 139s 303ms/step - loss: 0.6425 - accuracy: 0.7735 - val_loss: 0.6008 - val_accuracy: 0.7937\n",
      "Epoch 3/30\n",
      "460/460 [==============================] - 139s 303ms/step - loss: 0.4149 - accuracy: 0.8848 - val_loss: 0.5628 - val_accuracy: 0.8246\n",
      "Epoch 4/30\n",
      "460/460 [==============================] - 139s 303ms/step - loss: 0.2927 - accuracy: 0.9185 - val_loss: 0.5490 - val_accuracy: 0.8521\n",
      "Epoch 5/30\n",
      "460/460 [==============================] - 139s 301ms/step - loss: 0.2470 - accuracy: 0.9267 - val_loss: 0.4424 - val_accuracy: 0.8846\n",
      "Epoch 6/30\n",
      "460/460 [==============================] - 138s 301ms/step - loss: 0.2324 - accuracy: 0.9320 - val_loss: 1.0354 - val_accuracy: 0.8124\n",
      "Epoch 7/30\n",
      "460/460 [==============================] - 139s 302ms/step - loss: 0.2236 - accuracy: 0.9309 - val_loss: 0.4377 - val_accuracy: 0.8914\n",
      "Epoch 8/30\n",
      "460/460 [==============================] - 141s 307ms/step - loss: 0.2015 - accuracy: 0.9351 - val_loss: 0.5854 - val_accuracy: 0.8592\n",
      "Epoch 9/30\n",
      "460/460 [==============================] - 139s 301ms/step - loss: 0.1824 - accuracy: 0.9425 - val_loss: 0.3627 - val_accuracy: 0.9091\n",
      "Epoch 10/30\n",
      "460/460 [==============================] - 137s 298ms/step - loss: 0.1976 - accuracy: 0.9388 - val_loss: 0.3552 - val_accuracy: 0.9053\n",
      "Epoch 11/30\n",
      "460/460 [==============================] - 138s 300ms/step - loss: 0.1724 - accuracy: 0.9412 - val_loss: 0.4200 - val_accuracy: 0.8992\n",
      "Epoch 12/30\n",
      "460/460 [==============================] - 137s 297ms/step - loss: 0.1753 - accuracy: 0.9382 - val_loss: 0.3541 - val_accuracy: 0.9094\n",
      "Epoch 13/30\n",
      "460/460 [==============================] - 139s 303ms/step - loss: 0.1723 - accuracy: 0.9422 - val_loss: 0.5932 - val_accuracy: 0.8795\n",
      "Epoch 14/30\n",
      "460/460 [==============================] - 136s 295ms/step - loss: 0.1611 - accuracy: 0.9472 - val_loss: 0.3562 - val_accuracy: 0.9084\n",
      "Epoch 15/30\n",
      "460/460 [==============================] - 137s 298ms/step - loss: 0.1615 - accuracy: 0.9452 - val_loss: 0.3442 - val_accuracy: 0.9040\n",
      "Epoch 16/30\n",
      "460/460 [==============================] - 141s 306ms/step - loss: 0.1577 - accuracy: 0.9478 - val_loss: 0.5481 - val_accuracy: 0.9026\n",
      "Epoch 17/30\n",
      "460/460 [==============================] - 143s 311ms/step - loss: 0.1628 - accuracy: 0.9453 - val_loss: 0.6390 - val_accuracy: 0.8819\n",
      "Epoch 18/30\n",
      "460/460 [==============================] - 138s 301ms/step - loss: 0.1544 - accuracy: 0.9438 - val_loss: 0.3215 - val_accuracy: 0.9169\n",
      "Epoch 19/30\n",
      "460/460 [==============================] - 139s 303ms/step - loss: 0.1450 - accuracy: 0.9476 - val_loss: 0.4254 - val_accuracy: 0.9070\n",
      "Epoch 20/30\n",
      "460/460 [==============================] - 139s 303ms/step - loss: 0.1505 - accuracy: 0.9508 - val_loss: 0.5244 - val_accuracy: 0.8985\n",
      "Epoch 21/30\n",
      "460/460 [==============================] - 140s 304ms/step - loss: 0.1694 - accuracy: 0.9461 - val_loss: 0.5061 - val_accuracy: 0.9084\n",
      "Epoch 22/30\n",
      "460/460 [==============================] - 135s 293ms/step - loss: 0.1521 - accuracy: 0.9475 - val_loss: 0.5218 - val_accuracy: 0.9013\n",
      "Epoch 23/30\n",
      "460/460 [==============================] - 136s 295ms/step - loss: 0.1458 - accuracy: 0.9471 - val_loss: 0.5346 - val_accuracy: 0.9128\n",
      "Epoch 24/30\n",
      "460/460 [==============================] - 132s 288ms/step - loss: 0.1493 - accuracy: 0.9489 - val_loss: 0.5074 - val_accuracy: 0.9013\n",
      "Epoch 25/30\n",
      "460/460 [==============================] - 135s 293ms/step - loss: 0.1501 - accuracy: 0.9497 - val_loss: 0.3227 - val_accuracy: 0.9138\n",
      "Epoch 26/30\n",
      "460/460 [==============================] - 134s 291ms/step - loss: 0.1588 - accuracy: 0.9440 - val_loss: 0.4176 - val_accuracy: 0.9220\n",
      "Epoch 27/30\n",
      "460/460 [==============================] - 130s 282ms/step - loss: 0.1461 - accuracy: 0.9508 - val_loss: 0.5272 - val_accuracy: 0.9155\n",
      "Epoch 28/30\n",
      "460/460 [==============================] - 134s 291ms/step - loss: 0.1521 - accuracy: 0.9463 - val_loss: 0.6083 - val_accuracy: 0.9091\n",
      "Epoch 29/30\n",
      "460/460 [==============================] - 144s 312ms/step - loss: 0.1484 - accuracy: 0.9460 - val_loss: 0.5929 - val_accuracy: 0.9050\n",
      "Epoch 30/30\n",
      "460/460 [==============================] - 131s 285ms/step - loss: 0.1445 - accuracy: 0.9479 - val_loss: 0.4239 - val_accuracy: 0.9097\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "lstm_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "lstm_History= lstm_model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd069f",
   "metadata": {},
   "source": [
    "### Regularized multi-layer LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a325c1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 128, 32)           5376      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128, 32)           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 28)                6832      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 28)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 174       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,382\n",
      "Trainable params: 12,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "# Initiliazing the sequential model\n",
    "reg_lstm_model = Sequential()\n",
    "# Configuring the parameters\n",
    "reg_lstm_model.add(LSTM(32,recurrent_regularizer=l2(0.003),return_sequences=True,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "reg_lstm_model.add(Dropout(0.5))\n",
    "\n",
    "reg_lstm_model.add(LSTM(28,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "reg_lstm_model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "reg_lstm_model.add(Dense(n_classes, activation='sigmoid'))\n",
    "reg_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8b9d75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "460/460 [==============================] - 149s 300ms/step - loss: 1.1724 - accuracy: 0.5204 - val_loss: 0.8613 - val_accuracy: 0.6447\n",
      "Epoch 2/10\n",
      "460/460 [==============================] - 129s 280ms/step - loss: 0.8142 - accuracy: 0.6420 - val_loss: 0.7711 - val_accuracy: 0.6583\n",
      "Epoch 3/10\n",
      "460/460 [==============================] - 126s 274ms/step - loss: 0.7660 - accuracy: 0.6810 - val_loss: 0.6799 - val_accuracy: 0.7374\n",
      "Epoch 4/10\n",
      "460/460 [==============================] - 133s 290ms/step - loss: 0.5964 - accuracy: 0.7968 - val_loss: 0.5781 - val_accuracy: 0.8049\n",
      "Epoch 5/10\n",
      "460/460 [==============================] - 130s 283ms/step - loss: 0.5083 - accuracy: 0.8293 - val_loss: 0.5297 - val_accuracy: 0.8185\n",
      "Epoch 6/10\n",
      "460/460 [==============================] - 129s 281ms/step - loss: 0.4014 - accuracy: 0.8762 - val_loss: 0.4422 - val_accuracy: 0.8480\n",
      "Epoch 7/10\n",
      "460/460 [==============================] - 130s 283ms/step - loss: 0.4613 - accuracy: 0.8662 - val_loss: 0.4580 - val_accuracy: 0.8524\n",
      "Epoch 8/10\n",
      "460/460 [==============================] - 130s 284ms/step - loss: 0.4373 - accuracy: 0.8717 - val_loss: 0.5323 - val_accuracy: 0.8185\n",
      "Epoch 9/10\n",
      "460/460 [==============================] - 130s 283ms/step - loss: 0.3765 - accuracy: 0.8925 - val_loss: 0.4433 - val_accuracy: 0.8605\n",
      "Epoch 10/10\n",
      "460/460 [==============================] - 132s 287ms/step - loss: 0.3287 - accuracy: 0.9048 - val_loss: 0.4095 - val_accuracy: 0.8741\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "reg_lstm_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "reg_lstm_History= reg_lstm_model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44194f6",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Using Hyperas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b94d1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(36)\n",
    "tf.random.set_seed(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6acc562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import keras\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.utils import eval_hyperopt_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24be3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # Data directory\n",
    "    DATADIR= os.path.join(os.getcwd(), 'datasets', 'UCI_HAR_Dataset')\n",
    "    SIGNALS= [\"body_acc_x\", \"body_acc_y\", \"body_acc_z\",\n",
    "        \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\",\n",
    "        \"total_acc_x\", \"total_acc_y\", \"total_acc_z\"]    # Raw data signals\n",
    "\n",
    "    def _read_csv(filename):\n",
    "        return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "    def load_signals(subset):\n",
    "        signals_data = []\n",
    "        for signal in SIGNALS:\n",
    "            filename= DATADIR + f'/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "            signals_data.append(pd.read_csv(filename, delim_whitespace=True, header=None).values) \n",
    "        return np.transpose(signals_data, (1, 2, 0))\n",
    "    \n",
    "    def load_y(subset):\n",
    "        \"\"\"\n",
    "        The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "        that represents a human activity. We return a binary representation of \n",
    "        every sample objective as a 6 bits vector using One Hot Encoding\n",
    "        (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "        \"\"\"\n",
    "        filename= DATADIR + f'/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "        y = _read_csv(filename)[0]\n",
    "        return pd.get_dummies(y).values\n",
    "    \n",
    "    X_train, X_val = load_signals('train'), load_signals('test')\n",
    "    Y_train, Y_val = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a602070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_val, Y_val):\n",
    "    # Importing tensorflow\n",
    "    np.random.seed(36)\n",
    "    import tensorflow as tf\n",
    "    tf.random.set_seed(36)\n",
    "\n",
    "    # Initiliazing the sequential model\n",
    "    model= Sequential() \n",
    "    # if {{choice(['one', 'two'])}} == 'two':\n",
    "    if (random.choice(['one', 'two']) == 'two'):\n",
    "        # Configuring the parameters\n",
    "        model.add(LSTM(random.choice([28,32,38]), recurrent_regularizer= l2(random.uniform(0,0.0002)), \\\n",
    "            return_sequences=True, input_shape=(128, 9),name='LSTM2_1'))\n",
    "        # Adding a dropout layer\n",
    "        model.add(Dropout(random.uniform(0.35,0.65), name='Dropout2_1'))\n",
    "        model.add(LSTM(random.choice([26,32,36]), recurrent_regularizer= l2(random.uniform(0,0.001)),\\\n",
    "            input_shape=(128, 9),name='LSTM2_2'))\n",
    "        model.add(Dropout(random.uniform(0.5,0.7), name='Dropout2_2'))\n",
    "        # Adding a dense output layer with sigmoid activation\n",
    "        model.add(Dense(6, activation='sigmoid'))\n",
    "    else:\n",
    "        # Configuring the parameters\n",
    "        model.add(LSTM(random.choice([28,32,36]), recurrent_regularizer= l2(random.uniform(0,0.001)),input_shape=(128, 9),name='LSTM1_1'))\n",
    "        # Adding a dropout layer\n",
    "        model.add(Dropout(random.uniform(0.35,0.55),name='Dropout1_1'))\n",
    "        # Adding a dense output layer with sigmoid activation\n",
    "        model.add(Dense(6, activation='sigmoid'))\n",
    "        \n",
    "    adam= keras.optimizers.Adam(learning_rate= random.uniform(0.009,0.025))\n",
    "    rmsprop= keras.optimizers.RMSprop(learning_rate= random.uniform(0.009,0.025))\n",
    "    choiceval = random.choice(['adam', 'rmsprop'])\n",
    "    \n",
    "    if choiceval == 'adam':\n",
    "        optim = adam\n",
    "    else:\n",
    "        optim = rmsprop\n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
    "\n",
    "    result= model.fit(X_train, Y_train,\n",
    "              batch_size=16,\n",
    "              epochs=30,\n",
    "              verbose=1,\n",
    "              validation_data=(X_val, Y_val))\n",
    "                       \n",
    "    score, acc= model.evaluate(X_val, Y_val, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    print('-------------------------------------------------------------------------------------')\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8fdb45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " LSTM2_1 (LSTM)              (None, 128, 32)           5376      \n",
      "                                                                 \n",
      " Dropout2_1 (Dropout)        (None, 128, 32)           0         \n",
      "                                                                 \n",
      " LSTM2_2 (LSTM)              (None, 36)                9936      \n",
      "                                                                 \n",
      " Dropout2_2 (Dropout)        (None, 36)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 222       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,534\n",
      "Trainable params: 15,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "460/460 [==============================] - 47s 93ms/step - loss: 1.3144 - accuracy: 0.4355 - val_loss: 1.1638 - val_accuracy: 0.4588\n",
      "Epoch 2/30\n",
      "257/460 [===============>..............] - ETA: 16s - loss: 0.9027 - accuracy: 0.5837"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train, Y_train, X_val, Y_val \u001b[38;5;241m=\u001b[39m data()\n\u001b[0;32m      2\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[1;32m----> 3\u001b[0m best_run, best_model, space \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mminimize(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      4\u001b[0m                                       data,\n\u001b[0;32m      5\u001b[0m                                       tpe\u001b[38;5;241m.\u001b[39msuggest,\n\u001b[0;32m      6\u001b[0m                                       \u001b[38;5;241m15\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                       trials)\n",
      "Cell \u001b[1;32mIn [16], line 40\u001b[0m, in \u001b[0;36mmodel\u001b[1;34m(X_train, Y_train, X_val, Y_val)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],optimizer\u001b[38;5;241m=\u001b[39moptim)\n\u001b[1;32m---> 40\u001b[0m result\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m score, acc\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_val, Y_val, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, acc)\n",
      "File \u001b[1;32m~\\Documents\\Git\\ConvAE_LSTM\\.convAE_lstm\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Documents\\Git\\ConvAE_LSTM\\.convAE_lstm\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Documents\\Git\\ConvAE_LSTM\\.convAE_lstm\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Documents\\Git\\ConvAE_LSTM\\.convAE_lstm\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Documents\\Git\\ConvAE_LSTM\\.convAE_lstm\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\Documents\\Git\\ConvAE_LSTM\\.convAE_lstm\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Git\\ConvAE_LSTM\\.convAE_lstm\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Documents\\Git\\ConvAE_LSTM\\.convAE_lstm\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\Documents\\Git\\ConvAE_LSTM\\.convAE_lstm\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = data()\n",
    "trials = Trials()\n",
    "best_run, best_model, space = optim.minimize(model(X_train, Y_train, X_val, Y_val),\n",
    "                                      data,\n",
    "                                      tpe.suggest,\n",
    "                                      15,\n",
    "                                      trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trials = dict()\n",
    "for t, trial in enumerate(trials):\n",
    "        vals = trial.get('misc').get('vals')\n",
    "        print('Model',t+1,'parameters')\n",
    "        print(vals)\n",
    "        print()\n",
    "        z = eval_hyperopt_space(space, vals)\n",
    "        total_trials['M'+str(t+1)] = z\n",
    "        print(z)\n",
    "        print('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31695e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST MODEL PARAMS\n",
    "total_trials['M14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb2395",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,val_acc = best_model.evaluate(X_val, Y_val, verbose=0)\n",
    "_,train_acc = best_model.evaluate(X_train, Y_train, verbose=0)\n",
    "print('Train_accuracy',val_acc)\n",
    "print('validation accuracy',val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cfff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix_rnn(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    #return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
    "    return metrics.confusion_matrix(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca03474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix_rnn(Y_val, best_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6dcec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cm = confusion_matrix_rnn(Y_val, best_model.predict(X_val))\n",
    "plot_confusion_matrix(cm, classes=labels, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Greens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c48160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".convAE_lstm",
   "language": "python",
   "name": ".convae_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
